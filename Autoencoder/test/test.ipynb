{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import the packages\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn.preprocessing as prep\n",
    "\n",
    "from CLASS.CLASS_AGN import *\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.misc import imsave\n",
    "\n",
    "flags = tf.app.flags\n",
    "flags.DEFINE_integer('nb_epochs', 20, 'the numbers of the epoch')\n",
    "flags.DEFINE_integer('batch_size', 128, 'the size of the batch')\n",
    "flags.DEFINE_integer('display_time', 1, 'the time of the display')\n",
    "flags.DEFINE_string('your_path', 'D:/Data Minning/train_code/train/Autoencoder/test', 'the path of you code')\n",
    "flags.DEFINE_string('optimizer', 'rmsp', 'choose the right optimizer')\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "def standard_scale(X_train, X_test):\n",
    "    preprocess = prep.StandardScaler().fit(X_train)\n",
    "    X_train = preprocess.transform(X_train)\n",
    "    X_test = preprocess.transform(X_test)\n",
    "    return X_train, X_test\n",
    "\n",
    "def get_batch_data(data, batch_size):\n",
    "    start_index = np.random.randint(0, len(data) - batch_size)\n",
    "    return data[start_index : start_index + batch_size]\n",
    "    \n",
    "def Save_Result():\n",
    "    if os.path.exists(os.path.dirname('result')):\n",
    "        os.rename('result','result_before')\n",
    "        os.mkdir('result')\n",
    "        path = os.getcwd()\n",
    "        #print(path)\n",
    "        paths = path + str('\\\\result')\n",
    "        #print(paths)\n",
    "        os.chdir(paths)\n",
    "        #print(os.getcwd())\n",
    "    else:\n",
    "        os.mkdir('result')\n",
    "        path = os.getcwd()\n",
    "        #print(path)\n",
    "        paths = path + str('\\\\result')\n",
    "        #print(paths)\n",
    "        os.chdir(paths)\n",
    "        #print(os.getcwd())\n",
    "        \n",
    "def Save_Origial():\n",
    "    if os.path.exists(os.path.dirname('origial')):\n",
    "        os.rename('origial','origial_before')\n",
    "        path = os.getcwd()\n",
    "        #print(path)\n",
    "        paths = path + str('\\\\origial')\n",
    "        #print(paths)\n",
    "        os.chdir(paths)\n",
    "        #print(os.getcwd())\n",
    "    else:\n",
    "        os.mkdir('origial')\n",
    "        path = os.getcwd()\n",
    "        #print(path)\n",
    "        paths = path + str('\\\\origial')\n",
    "        #print(paths)\n",
    "        os.chdir(paths)\n",
    "        #print(os.getcwd())\n",
    "        \n",
    "def Save_transform():\n",
    "    if os.path.exists(os.path.dirname('transform')):\n",
    "        os.rename('transform','transform_before')\n",
    "        path = os.getcwd()\n",
    "        #print(path)\n",
    "        paths = path + str('\\\\transform')\n",
    "        #print(paths)\n",
    "        os.chdir(paths)\n",
    "        #print(os.getcwd())\n",
    "    else:\n",
    "        os.mkdir('transform')\n",
    "        path = os.getcwd()\n",
    "        #print(path)\n",
    "        paths = path + str('\\\\transform')\n",
    "        #print(paths)\n",
    "        os.chdir(paths)\n",
    "        #print(os.getcwd())\n",
    "        \n",
    "def choose_optimizer(name):\n",
    "    if name == 'sgd':\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.001)\n",
    "    elif name == 'adam':\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate = 0.001)\n",
    "    elif name == 'adag':\n",
    "        optimizer = tf.train.AdagradOptimizer(learning_rate = 0.001)\n",
    "    elif name == 'adad':\n",
    "        optimizer = tf.train.AdadeltaOptimizer(learning_rate = 0.001)\n",
    "    elif name == 'rmsp':\n",
    "        optimizer = tf.train.RMSPropOptimizer(learning_rate = 0.001)\n",
    "    else:\n",
    "        print('please add you optimizer...')\n",
    "        raise Exception('Error...')\n",
    "    return optimizer\n",
    "    \n",
    "def print_information(cost, epoch):\n",
    "    plt.xlabel('the number of each epoch')\n",
    "    plt.ylabel('the cost of each epoch')\n",
    "    plt.title('the picture of the cost')\n",
    "    plt.plot(epoch, cost)\n",
    "    plt.show() \n",
    "    print('ending...')\n",
    "    \n",
    "#def main(unused_argv):\n",
    "def main(_):\n",
    "    start_time = time.time()\n",
    "    print('starting...')\n",
    "    print('loding data,please wait a moment...')\n",
    "    #print('\\n')\n",
    "    \n",
    "    mnist = input_data.read_data_sets('MNIST_data', one_hot = True)\n",
    "    n_samples = int(mnist.train.num_examples)\n",
    "    \n",
    "    # load the mnist datasets and print the shape\n",
    "    X_train, X_test = standard_scale(mnist.train.images, mnist.test.images)\n",
    "    print(mnist.train.images.shape)\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    #print('\\n')\n",
    "    \n",
    "    # Instance an object\n",
    "    autoencoder = AdditiveGaussianNoiseAutoencoder(n_input = 784,\n",
    "                                                   n_hidden = 256,\n",
    "                                                   transfer_function = tf.nn.relu,\n",
    "                                                   optimizer = choose_optimizer(name = FLAGS.optimizer),\n",
    "                                                   scale = 0.01)\n",
    "    # save the origial pictures\n",
    "    Save_Origial()\n",
    "    for epoch1 in range(FLAGS.nb_epochs):\n",
    "        total_batch = int(n_samples / FLAGS.batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_data = get_batch_data(X_train, FLAGS.batch_size)\n",
    "            origial = np.reshape(batch_data, [128, 28, 28, -1])\n",
    "            origial_picture = origial[1:2]\n",
    "            origial_result = np.reshape(origial_picture, [28, 28])\n",
    "            imsave('%d.jpg' %(i), origial_result)\n",
    "    # get back to the upper path \n",
    "    path = FLAGS.your_path\n",
    "    print('start saving the origial pictures...')\n",
    "    print(path)\n",
    "    os.chdir(path)\n",
    "    \n",
    "    # save the result of the hidden layer\n",
    "    Save_transform()\n",
    "    for epoch1 in range(FLAGS.nb_epochs):\n",
    "        total_batch = int(n_samples / FLAGS.batch_size)\n",
    "        for j in range(total_batch):\n",
    "            batch_data = get_batch_data(X_train, FLAGS.batch_size)\n",
    "            transforms = autoencoder.transform(batch_data)\n",
    "            transform = np.reshape(transforms, [128, 16, 16, -1])\n",
    "            transform_picture = transform[1:2]\n",
    "            transform_result = np.reshape(transform_picture, [16, 16])\n",
    "            imsave('%d.jpg' %(j), transform_result)\n",
    "    # get back to the upper path \n",
    "    path = FLAGS.your_path\n",
    "    print('start saving the hidden layers pictures...')\n",
    "    print(path)\n",
    "    os.chdir(path)\n",
    "          \n",
    "    # save the reconstraction pictures    \n",
    "    Save_Result()\n",
    "    cost_value = []\n",
    "    epochs = []\n",
    "    for epoch in range(FLAGS.nb_epochs):\n",
    "        total_batch = int(n_samples / FLAGS.batch_size)\n",
    "        avg_cost = 0.\n",
    "        for k in range(total_batch):\n",
    "            batch_data = get_batch_data(X_train, FLAGS.batch_size)\n",
    "            cost = autoencoder.once_fit(batch_data)\n",
    "            avg_cost += cost / n_samples * FLAGS.batch_size\n",
    "            reconstract = autoencoder.reconstraion(batch_data) \n",
    "            picture = np.reshape(reconstract, [128, 28, 28, -1])\n",
    "            result = picture[1:2]\n",
    "            data = np.reshape(result, [28, 28])\n",
    "            imsave('%d.jpg' %(k), data)\n",
    "            \n",
    "        cost_value.append(cost)\n",
    "        epochs.append(epoch)\n",
    "        \n",
    "        if epoch % FLAGS.display_time == 0:\n",
    "            print('Epoch:', '%04d' %(epoch + 1), 'cost =','{:.9f}'.format(avg_cost))\n",
    "    print('Total cost is: ' + str(autoencoder.calc_total_cost(X_test)))\n",
    "    print_information(cost = cost_value, epoch = epochs)\n",
    "    print('Total time is %d s' %(time.time() - start_time))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()\n",
    "    sys.exit(0)\n",
    "    #tf.app.run(main=None, argv=None)\n",
    "    #AGN_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import the packages\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn.preprocessing as prep\n",
    "\n",
    "from CLASS.CLASS_MNA import *\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.misc import imsave\n",
    "\n",
    "flags = tf.app.flags\n",
    "flags.DEFINE_integer('nb_epochs', 20, 'the numbers of the epoch')\n",
    "flags.DEFINE_integer('batch_size', 128, 'the size of the batch')\n",
    "flags.DEFINE_integer('display_time', 1, 'the time of the display')\n",
    "flags.DEFINE_string('your_path', 'D:/Data Minning/train_code/train/Autoencoder/test', 'the path of you code')\n",
    "flags.DEFINE_string('optimizer', 'adam', 'choose the right optimizer')\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "def standard_scale(X_train, X_test):\n",
    "    preprocess = prep.StandardScaler().fit(X_train)\n",
    "    X_train = preprocess.transform(X_train)\n",
    "    X_test = preprocess.transform(X_test)\n",
    "    return X_train, X_test\n",
    "\n",
    "def get_batch_data(data, batch_size):\n",
    "    start_index = np.random.randint(0, len(data) - batch_size)\n",
    "    return data[start_index : start_index + batch_size]\n",
    "    \n",
    "def Save_Result():\n",
    "    if os.path.exists(os.path.dirname('result_MNA')):\n",
    "        os.rename('result_MNA','result_MNA_before')\n",
    "        os.mkdir('result_MNA')\n",
    "        path = os.getcwd()\n",
    "        #print(path)\n",
    "        paths = path + str('\\\\result_MNA')\n",
    "        #print(paths)\n",
    "        os.chdir(paths)\n",
    "        #print(os.getcwd())\n",
    "    else:\n",
    "        os.mkdir('result_MNA')\n",
    "        path = os.getcwd()\n",
    "        #print(path)\n",
    "        paths = path + str('\\\\result_MNA')\n",
    "        #print(paths)\n",
    "        os.chdir(paths)\n",
    "        #print(os.getcwd())\n",
    "        \n",
    "def Save_Origial():\n",
    "    if os.path.exists(os.path.dirname('origial_MNA')):\n",
    "        os.rename('origial_MNA','origial_before_MNA')\n",
    "        path = os.getcwd()\n",
    "        #print(path)\n",
    "        paths = path + str('\\\\origial_MNA')\n",
    "        #print(paths)\n",
    "        os.chdir(paths)\n",
    "        #print(os.getcwd())\n",
    "    else:\n",
    "        os.mkdir('origial_MNA')\n",
    "        path = os.getcwd()\n",
    "        #print(path)\n",
    "        paths = path + str('\\\\origial_MNA')\n",
    "        #print(paths)\n",
    "        os.chdir(paths)\n",
    "        #print(os.getcwd())\n",
    "        \n",
    "def Save_transform():\n",
    "    if os.path.exists(os.path.dirname('transform_MNA')):\n",
    "        os.rename('transform_MNA','transform_before_MNA')\n",
    "        path = os.getcwd()\n",
    "        #print(path)\n",
    "        paths = path + str('\\\\transform_MNA')\n",
    "        #print(paths)\n",
    "        os.chdir(paths)\n",
    "        #print(os.getcwd())\n",
    "    else:\n",
    "        os.mkdir('transform_MNA')\n",
    "        path = os.getcwd()\n",
    "        #print(path)\n",
    "        paths = path + str('\\\\transform_MNA')\n",
    "        #print(paths)\n",
    "        os.chdir(paths)\n",
    "        #print(os.getcwd())\n",
    "        \n",
    "def choose_optimizer(name):\n",
    "    if name == 'sgd':\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.001)\n",
    "    elif name == 'adam':\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate = 0.001)\n",
    "    elif name == 'adag':\n",
    "        optimizer = tf.train.AdagradOptimizer(learning_rate = 0.001)\n",
    "    elif name == 'adad':\n",
    "        optimizer = tf.train.AdadeltaOptimizer(learning_rate = 0.001)\n",
    "    elif name == 'rmsp':\n",
    "        optimizer = tf.train.RMSPropOptimizer(learning_rate = 0.001)\n",
    "    else:\n",
    "        print('please add you optimizer...')\n",
    "        raise Exception('Error...')\n",
    "    return optimizer\n",
    "    \n",
    "def print_information(cost, epoch):\n",
    "    plt.xlabel('the number of each epoch')\n",
    "    plt.ylabel('the cost of each epoch')\n",
    "    plt.title('the picture of the cost')\n",
    "    plt.plot(epoch, cost)\n",
    "    plt.show() \n",
    "    print('ending...')\n",
    "    \n",
    "#def main(unused_argv):\n",
    "def main(_):\n",
    "    start_time = time.time()\n",
    "    print('starting...')\n",
    "    print('loding data,please wait a moment...')\n",
    "    #print('\\n')\n",
    "    \n",
    "    mnist = input_data.read_data_sets('MNIST_data', one_hot = True)\n",
    "    n_samples = int(mnist.train.num_examples)\n",
    "    \n",
    "    # load the mnist datasets and print the shape\n",
    "    X_train, X_test = standard_scale(mnist.train.images, mnist.test.images)\n",
    "    print(mnist.train.images.shape)\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    #print('\\n')\n",
    "    \n",
    "    # Instance an object\n",
    "    autoencoder = MaskingNoiseAutoencoder(n_input = 784,\n",
    "                                          n_hidden = 256,\n",
    "                                          transfer_function = tf.nn.softplus,\n",
    "                                          optimizer = choose_optimizer(name = FLAGS.optimizer),\n",
    "                                          dropout_probability = 0.95)\n",
    "    # save the origial pictures\n",
    "    Save_Origial()\n",
    "    for epoch1 in range(FLAGS.nb_epochs):\n",
    "        total_batch = int(n_samples / FLAGS.batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_data = get_batch_data(X_train, FLAGS.batch_size)\n",
    "            origial = np.reshape(batch_data, [128, 28, 28, -1])\n",
    "            origial_picture = origial[1:2]\n",
    "            origial_result = np.reshape(origial_picture, [28, 28])\n",
    "            imsave('%d.jpg' %(i), origial_result)\n",
    "    # get back to the upper path \n",
    "    path = FLAGS.your_path\n",
    "    print('start saving the origial pictures...')\n",
    "    print(path)\n",
    "    os.chdir(path)\n",
    "    \n",
    "    # save the result of the hidden layer\n",
    "    Save_transform()\n",
    "    for epoch1 in range(FLAGS.nb_epochs):\n",
    "        total_batch = int(n_samples / FLAGS.batch_size)\n",
    "        for j in range(total_batch):\n",
    "            batch_data = get_batch_data(X_train, FLAGS.batch_size)\n",
    "            transforms = autoencoder.transform(batch_data)\n",
    "            #print(transforms.shape)\n",
    "            transform = np.reshape(transforms, [128, 16, 16, -1])\n",
    "            transform_picture = transform[1:2]\n",
    "            transform_result = np.reshape(transform_picture, [16, 16])\n",
    "            imsave('%d.jpg' %(j), transform_result)\n",
    "    # get back to the upper path \n",
    "    path = FLAGS.your_path\n",
    "    print('start saving the hidden layers pictures...')\n",
    "    print(path)\n",
    "    os.chdir(path)\n",
    "          \n",
    "    # save the reconstraction pictures    \n",
    "    Save_Result()\n",
    "    cost_value = []\n",
    "    epochs = []\n",
    "    for epoch in range(FLAGS.nb_epochs):\n",
    "        total_batch = int(n_samples / FLAGS.batch_size)\n",
    "        avg_cost = 0.\n",
    "        for k in range(total_batch):\n",
    "            batch_data = get_batch_data(X_train, FLAGS.batch_size)\n",
    "            cost = autoencoder.partial_fit(batch_data)\n",
    "            avg_cost += cost / n_samples * FLAGS.batch_size\n",
    "            reconstract = autoencoder.reconstruct(batch_data) \n",
    "            picture = np.reshape(reconstract, [128, 28, 28, -1])\n",
    "            result = picture[1:2]\n",
    "            data = np.reshape(result, [28, 28])\n",
    "            imsave('%d.jpg' %(k), data)\n",
    "            \n",
    "        cost_value.append(cost)\n",
    "        epochs.append(epoch)\n",
    "        \n",
    "        if epoch % FLAGS.display_time == 0:\n",
    "            print('Epoch:', '%04d' %(epoch + 1), 'cost =','{:.9f}'.format(avg_cost))\n",
    "    print('Total cost is: ' + str(autoencoder.calc_total_cost(X_test)))\n",
    "    print_information(cost = cost_value, epoch = epochs)\n",
    "    print('Total time is %d s' %(time.time() - start_time))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()\n",
    "    #sys.exit(0)\n",
    "    #tf.app.run(main=None, argv=None)\n",
    "    #AGN_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import the packages\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn.preprocessing as prep\n",
    "\n",
    "from CLASS.CLASS_VAE import *\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.misc import imsave\n",
    "\n",
    "flags = tf.app.flags\n",
    "flags.DEFINE_integer('nb_epochs', 20, 'the numbers of the epoch')\n",
    "flags.DEFINE_integer('batch_size', 128, 'the size of the batch')\n",
    "flags.DEFINE_integer('display_time', 1, 'the time of the display')\n",
    "flags.DEFINE_float('learning_rate', 0.001, 'the learning rate of the optimizer')\n",
    "flags.DEFINE_string('your_path', 'D:/Data Minning/train_code/train/Autoencoder/test', 'the path of you code')\n",
    "flags.DEFINE_string('optimizer', 'adag', 'choose the right optimizer')\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "def standard_scale(X_train, X_test):\n",
    "    preprocess = prep.StandardScaler().fit(X_train)\n",
    "    X_train = preprocess.transform(X_train)\n",
    "    X_test = preprocess.transform(X_test)\n",
    "    return X_train, X_test\n",
    "\n",
    "def get_batch_data(data, batch_size):\n",
    "    start_index = np.random.randint(0, len(data) - batch_size)\n",
    "    return data[start_index : start_index + batch_size]\n",
    "    \n",
    "def Save_Result():\n",
    "    if os.path.exists(os.path.dirname('result_VAE')):\n",
    "        os.rename('result_VAE','result_VAE_before')\n",
    "        os.mkdir('result_VAE')\n",
    "        path = os.getcwd()\n",
    "        #print(path)\n",
    "        paths = path + str('\\\\result_VAE')\n",
    "        #print(paths)\n",
    "        os.chdir(paths)\n",
    "        #print(os.getcwd())\n",
    "    else:\n",
    "        os.mkdir('result_VAE')\n",
    "        path = os.getcwd()\n",
    "        #print(path)\n",
    "        paths = path + str('\\\\result_VAE')\n",
    "        #print(paths)\n",
    "        os.chdir(paths)\n",
    "        #print(os.getcwd())\n",
    "        \n",
    "def Save_Origial():\n",
    "    if os.path.exists(os.path.dirname('origial_VAE')):\n",
    "        os.rename('origial_VAE','origial_before_VAE')\n",
    "        path = os.getcwd()\n",
    "        #print(path)\n",
    "        paths = path + str('\\\\origial_VAE')\n",
    "        #print(paths)\n",
    "        os.chdir(paths)\n",
    "        #print(os.getcwd())\n",
    "    else:\n",
    "        os.mkdir('origial_VAE')\n",
    "        path = os.getcwd()\n",
    "        #print(path)\n",
    "        paths = path + str('\\\\origial_VAE')\n",
    "        #print(paths)\n",
    "        os.chdir(paths)\n",
    "        #print(os.getcwd())\n",
    "        \n",
    "def Save_transform():\n",
    "    if os.path.exists(os.path.dirname('transform_VAE')):\n",
    "        os.rename('transform_VAE','transform_before_VAE')\n",
    "        path = os.getcwd()\n",
    "        #print(path)\n",
    "        paths = path + str('\\\\transform_VAE')\n",
    "        #print(paths)\n",
    "        os.chdir(paths)\n",
    "        #print(os.getcwd())\n",
    "    else:\n",
    "        os.mkdir('transform_VAE')\n",
    "        path = os.getcwd()\n",
    "        #print(path)\n",
    "        paths = path + str('\\\\transform_VAE')\n",
    "        #print(paths)\n",
    "        os.chdir(paths)\n",
    "        #print(os.getcwd())\n",
    "        \n",
    "def choose_optimizer(name):\n",
    "    if name == 'sgd':\n",
    "        optimizer = tf.train.GradientDescentOptimizer(FLAGS.learning_rate)\n",
    "    elif name == 'adam':\n",
    "        optimizer = tf.train.AdamOptimizer(FLAGS.learning_rate)\n",
    "    elif name == 'adag':\n",
    "        optimizer = tf.train.AdagradOptimizer(FLAGS.learning_rate)\n",
    "    elif name == 'adad':\n",
    "        optimizer = tf.train.AdadeltaOptimizer(FLAGS.learning_rate)\n",
    "    elif name == 'rmsp':\n",
    "        optimizer = tf.train.RMSPropOptimizer(FLAGS.learning_rate)\n",
    "    else:\n",
    "        print('please add you optimizer...')\n",
    "        raise Exception('Error...')\n",
    "    return optimizer\n",
    "    \n",
    "def print_information(cost, epoch):\n",
    "    plt.xlabel('the number of each epoch')\n",
    "    plt.ylabel('the cost of each epoch')\n",
    "    plt.title('the picture of the cost')\n",
    "    plt.plot(epoch, cost)\n",
    "    plt.show() \n",
    "    print('ending...')\n",
    "    \n",
    "#def main(unused_argv):\n",
    "def main(_):\n",
    "    start_time = time.time()\n",
    "    print('starting...')\n",
    "    print('loding data,please wait a moment...')\n",
    "    #print('\\n')\n",
    "    \n",
    "    mnist = input_data.read_data_sets('MNIST_data', one_hot = True)\n",
    "    n_samples = int(mnist.train.num_examples)\n",
    "    \n",
    "    # load the mnist datasets and print the shape\n",
    "    X_train, X_test = standard_scale(mnist.train.images, mnist.test.images)\n",
    "    print(mnist.train.images.shape)\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    #print('\\n')\n",
    "    \n",
    "    # Instance an object\n",
    "    autoencoder = VariationalAutoencoder(n_input = 784,\n",
    "                                         n_hidden = 256,\n",
    "                                         optimizer = choose_optimizer(name = FLAGS.optimizer))\n",
    "    # save the origial pictures\n",
    "    Save_Origial()\n",
    "    for epoch1 in range(FLAGS.nb_epochs):\n",
    "        total_batch = int(n_samples / FLAGS.batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_data = get_batch_data(X_train, FLAGS.batch_size)\n",
    "            origial = np.reshape(batch_data, [128, 28, 28, -1])\n",
    "            origial_picture = origial[1:2]\n",
    "            origial_result = np.reshape(origial_picture, [28, 28])\n",
    "            imsave('%d.jpg' %(i), origial_result)\n",
    "    # get back to the upper path \n",
    "    path = FLAGS.your_path\n",
    "    print('start saving the origial pictures...')\n",
    "    print(path)\n",
    "    os.chdir(path)\n",
    "    \n",
    "    # save the result of the hidden layer\n",
    "    Save_transform()\n",
    "    for epoch1 in range(FLAGS.nb_epochs):\n",
    "        total_batch = int(n_samples / FLAGS.batch_size)\n",
    "        for j in range(total_batch):\n",
    "            batch_data = get_batch_data(X_train, FLAGS.batch_size)\n",
    "            transforms = autoencoder.transform(batch_data)\n",
    "            #print(transforms.shape)\n",
    "            transform = np.reshape(transforms, [128, 16, 16, -1])\n",
    "            transform_picture = transform[1:2]\n",
    "            transform_result = np.reshape(transform_picture, [16, 16])\n",
    "            imsave('%d.jpg' %(j), transform_result)\n",
    "    # get back to the upper path \n",
    "    path = FLAGS.your_path\n",
    "    print('start saving the hidden layers pictures...')\n",
    "    print(path)\n",
    "    os.chdir(path)\n",
    "          \n",
    "    # save the reconstraction pictures    \n",
    "    Save_Result()\n",
    "    cost_value = []\n",
    "    epochs = []\n",
    "    for epoch in range(FLAGS.nb_epochs):\n",
    "        total_batch = int(n_samples / FLAGS.batch_size)\n",
    "        avg_cost = 0.\n",
    "        for k in range(total_batch):\n",
    "            batch_data = get_batch_data(X_train, FLAGS.batch_size)\n",
    "            cost = autoencoder.partial_fit(batch_data)\n",
    "            avg_cost += cost / n_samples * FLAGS.batch_size\n",
    "            reconstract = autoencoder.reconstruct(batch_data) \n",
    "            picture = np.reshape(reconstract, [128, 28, 28, -1])\n",
    "            result = picture[1:2]\n",
    "            data = np.reshape(result, [28, 28])\n",
    "            imsave('%d.jpg' %(k), data)\n",
    "            \n",
    "        cost_value.append(cost)\n",
    "        epochs.append(epoch)\n",
    "        \n",
    "        if epoch % FLAGS.display_time == 0:\n",
    "            print('Epoch:', '%04d' %(epoch + 1), 'cost =','{:.9f}'.format(avg_cost))\n",
    "    print('Total cost is: ' + str(autoencoder.calc_total_cost(X_test)))\n",
    "    print_information(cost = cost_value, epoch = epochs)\n",
    "    print('Total time is %d s' %(time.time() - start_time))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()\n",
    "    #sys.exit(0)\n",
    "    #tf.app.run(main=None, argv=None)\n",
    "    #AGN_main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
